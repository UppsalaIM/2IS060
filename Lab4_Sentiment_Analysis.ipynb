{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 / Sentiment Analysis with NLTK\n",
    "\n",
    "<sup>This lab is based on https://github.com/lesley2958/twilio-sent-analysis</sup>\n",
    "\n",
    "Before we get started, we need to load the relevant Python modules that us used in the code later by running the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import somialabs.lab4\n",
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this lab:\n",
    "1. Follow the instructions running the code when asked.\n",
    "2. Discuss each question in your group.\n",
    "3. Keep notes for your answers to the questions in a separate MS Word document (you can use [this template](Lab4_answers_template.docx)).\n",
    "4. When completed, submit your answers to Studentportalen under Lab 4: http://www.uu.se/goto/vtda138.\n",
    "\n",
    "In this lab session, we will try out some *sentiment analysis* on Twitter data. So you might be asking, what exactly is \"sentiment analysis\"? \n",
    "\n",
    "Well, it's exactly what it sounds like: it's building a computational system to determine the emotional tone behind words. This is important because it allows you to gain an understanding of the attitudes, opinions, and emotions of the people in your data. At a higher level, sentiment analysis involves natural language processing and machine learning by taking the actual text element, transforming it into a format that a machine can read, and using statistics to determine the actual sentiment.\n",
    "\n",
    "In this lab, you will see how we can categorize Twitter posts as being positive or negative. You will also be able to experiment with different forms of data pre-processing to test the effects on the categorization of the posts and also try and see the effects of how we define positive and negative words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis isn't a new problem. There are thousands of labeled data out there, labels varying from simple positive and negative to more complex systems that determine *how* positive or negative is a given text. With that said, I've selected a pre-labeled set of data consisting of tweets from Twitter. Using this data, we'll begin by building a sentiment analysis model. \n",
    "\n",
    "## Building a sentiment analysis model (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement our classifier, we need the Twitter data in a format that allows us to feed it into the classifier model. We will convert the a corpus of tweets as text documents to a matrix of token counts (TDM). These vector counts will be what the classifier will ultimately use to train, like in the previous labs. We have two files, `pos_tweets.txt` and `neg_tweets.txt`, each containing positively and negatively oriented tweets respectively.\n",
    "\n",
    "Run the next code cell to view a sample of 20 positive tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somialabs.lab4.view_20_pos_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Looking at the sample of tweets above, what about them makes them *positively* orientated?\n",
    "\n",
    "Run the next code cell to view a sample of 20 negative tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somialabs.lab4.view_20_neg_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Looking at the sample of tweets above, what about them makes them *negatively* orientated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Formulate a simple way to calculate the sentiment categorisation (positive/negative) by analysing the words of a tweet. Give an example of your strategy by using one tweet from the samples above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do now is train a machine learning classifier based on labeled positive and negative tweets from our sampels above. While we *could* manually figure out what words are positive and negative this might take a long time to figure out, and there might also be some words that are not obviously implicit to either orientation. Luckily for us, we can do this computationally based on labelling whole tweets as pos/neg rather than identifying specific words.\n",
    "\n",
    "Next, let's create a Term Document Matrix (TDM) of our tweets. Run the next code cell to create a TDM from our tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somialabs.lab4.create_tdm_from_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** How might representing tweets as a TDM help us in training our sentiment classifier? Think about the distribution of pos/neg words and also neutral words.\n",
    "\n",
    "Run the following code cell that uses our TDM to build a logistic regression classifier, and outputs some examples of predicted labels based on analysing the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somialabs.lab4.view_log_regression_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Are there any mis-classifications in the output above? If so, for what reason do you think that our classifier has output some incorrect labels?\n",
    "\n",
    "Obviously we want to do more than just 'eyeball' the data, so let's actually calculate the accuracy score. Run the following code cell to output the accuracy score of the trained classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somialabs.lab4.view_log_regression_accuracy_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the point in creating a machine learning algorithm if you have no idea how it performs? When training a model we leeave some of the dataset for testing purposes. In the underlying code, there is a function that calculates the accuracy percentage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Is the accuracy of our classifier good or bad? Explain why you think this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** What strategies could we use to improve the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a sentiment analysis model (2)\n",
    "\n",
    "Next, we will build a similar model but the underlying code uses a different method called Naive Bayes. Naive Bayes basically uses probability statistics on the data and works by counting the frequencies of different words. Let's try it out on the same sample pos/neg tweets from above.\n",
    "\n",
    "Run the next code cell to train a Naive Bayes classifier and output the most informative features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somialabs.lab4.train_naive_bayes_and_show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that there are three columns. Column 1 indicates the presence of a word. What it does is count the number of occurences of each word for both labels to compute the ratio between the two, which is what column 3 represents. Column 2 lets us know which label occurs more frequently (the label on the left is the label most associated with the corresponding word.\n",
    "\n",
    "**Question 8.** Are all of these feature valid pos/neg indicators? How does the ratio of pos/neg indicated in column 3 help inform us on the overall sentiment of a tweet?\n",
    "\n",
    "Run the following code cell to interact with the trained classifier. Try changing the text to your own. The default is `Uppsala University if great!` but you can try other things like `PhD students are sad because they are overworked!` or `I have no worries!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somialabs.lab4.interact_naive_bayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9.** How does the Naive Bayes classifer perform with different text inputs? Experiment by entering your own text and see if you can force it to mis-classify your test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10.** How might you be able to further enhance a sentiment analysis model, based on what you have learned in this lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
